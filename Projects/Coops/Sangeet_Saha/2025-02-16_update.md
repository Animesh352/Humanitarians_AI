# Biweekly Report 2
**Name:** Sangeet Saha  
**Date Range:** February 3 – February 16  
**Team/Project Name:** Chain of Thought Multi-Agent Reasoning (Humanitarian AI)

## Hours
Total hours this period: 80

## Highlights
- Onboarded to the chain-of-thought agents project with two other team members.
- Participated in system architecture discussions, addressing scalability, reasoning tree depth, and response aggregation.
- Developed a minimal Gradio UI for multi-agent interaction with different LLMs.
- Integrated ChromaDB as the retrieval layer to enable RAG (Retrieval Augmented Generation) functionality.
- Explored and began testing Groq, a high-performance LLM inference service for hosted models like DeepSeek and LLaMA 3.3.
- Resolved inconsistent response formatting from LLMs by using Pydantic-based schema validation and mimicking tool outputs.

## In Progress
- Expanding Gradio UI for multi-agent reasoning workflows.
- Refining API interactions and ensuring cross-compatibility between Groq and Ollama.
- Collecting test cases for evaluating LLM coherence, consistency, and reasoning step clarity.

## Next Steps
- Implement endpoint layer for Groq with robust model-switching logic.
- Finalize agent interaction schemas for structured JSON output.
- Begin working on prompt engineering to improve consistency of reasoning chains.

## Team Interactions
### Wednesday Standups (9:00 AM):
- **Discussion Summary:** Discussed switching to Groq and issues with LLM outputs.
- **Feedback:** Suggested using Pydantic to ensure consistency and improve traceability of responses.
- **Demo Shared:** Live Gradio UI preview.

### Friday Standups (9:00 AM):
- **Discussion Summary:** Shared status of ChromaDB integration and Groq experiments.
- **Feedback:** Positive feedback on progress; advised to start thinking about merging reasoning steps.
- **Demo Shared:** ChromaDB RAG flow demo.

### Other Meetings/Collaborations:
- Feb 5: Groq API discussion; evaluating cost and latency vs Ollama.
- Feb 9: Agent system schema brainstorming—settled on JSON tree structure for chain of thought.

## Learnings & Reflections
- Gained hands-on experience with retrieval-augmented generation using ChromaDB.
- Understood the difference in LLM behavior when using local (Ollama) vs hosted (Groq) models.
- Learned how structured outputs (via Pydantic) can dramatically improve debugging in LLM systems.

## Blockers
- Formatting inconsistencies from different LLM providers.
- Latency and quota issues while testing large models on Groq.